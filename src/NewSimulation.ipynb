{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from Chain.Manager import Manager\n",
    "import random, numpy\n",
    "import Chain.Consensus.BigFoot.BigFoot as BigFoot\n",
    "import Chain.Consensus.PBFT.PBFT as PBFT\n",
    "from Chain.Metrics import SimulationState, Metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Chain.Parameters import Parameters\n",
    "import Chain.tools as tools\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Running simulation with Node=6, Validator=0.5, Protocol=PBFT, Runtime=1000, type=broadcast, beta=0.5, faulty_nodes=0, num_byzantine=0\n",
      "Simulation started...\n",
      "Simulation finished.\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m Runtime1 \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1000\u001b[39m]:\n\u001b[1;32m     78\u001b[0m                             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning simulation with Node=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNode1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validator=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mValidator1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Protocol=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mProtocol1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Runtime=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRuntime1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, beta=0.5, faulty_nodes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfaulty_nodes1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_byzantine=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber_byzantine1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m                             result \u001b[38;5;241m=\u001b[39m \u001b[43mrun1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNode1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValidator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mValidator1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProtocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mProtocol1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfaulty_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaulty_nodes1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_byzantine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_byzantine1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m                             results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Convert the results to a DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36mrun1\u001b[0;34m(Node, Validator, Protocol, type, beta, faulty_nodes, num_byzantine)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Open a text file for writing the report\u001b[39;00m\n\u001b[1;32m     44\u001b[0m SimulationState\u001b[38;5;241m.\u001b[39mstore_state(manager\u001b[38;5;241m.\u001b[39msim)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimulationState\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockchain_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Redirect stdout to a string buffer, print the metrics, and then reset stdout\u001b[39;00m\n\u001b[1;32m     48\u001b[0m old_stdout \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/Documents/GitHub/SymBChainSim101/src/Chain/Metrics.py:52\u001b[0m, in \u001b[0;36mMetrics.measure_all\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_all\u001b[39m(state):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_latency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     Metrics\u001b[38;5;241m.\u001b[39mmeasure_throughput(state)\n",
      "File \u001b[0;32m~/Documents/GitHub/SymBChainSim101/src/Chain/Metrics.py:94\u001b[0m, in \u001b[0;36mMetrics.measure_latency\u001b[0;34m(bc_state)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m node_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblockchain\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     90\u001b[0m     Metrics\u001b[38;5;241m.\u001b[39mlatency[node_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m][b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m     91\u001b[0m         [b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_added\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransactions\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     92\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m Metrics\u001b[38;5;241m.\u001b[39mlatency[node_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_lat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_lat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatency\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BlockChain/lib/python3.10/statistics.py:328\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    326\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean requires at least one data point\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    329\u001b[0m T, total, count \u001b[38;5;241m=\u001b[39m _sum(data)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m count \u001b[38;5;241m==\u001b[39m n\n",
      "\u001b[0;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the seed for random number generation\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def run1(Node=10, Validator=0.1, Protocol='BigFoot',type=\"broadcast\", beta=0.5,faulty_nodes=0,num_byzantine=0):\n",
    "    \"\"\"\n",
    "    Runs the simulation with the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    Node (int): The number of nodes in the simulation.\n",
    "    Validator (float): The probability of a node being a validator.\n",
    "    Protocol (str): The consensus protocol to use ('BigFoot' or 'PBFT').\n",
    "    Runtime (int): The runtime of the simulation in seconds.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Manager object and set up the simulation\n",
    "    manager = Manager()\n",
    "    tools.set_env_vars_from_config()\n",
    "    Parameters.load_params_from_config()\n",
    "    # Use the modify method to set the parameters\n",
    "    manager.modify('Nn', Node)\n",
    "    manager.modify('alpha', Validator)\n",
    "    manager.modify('init_CP', Protocol)\n",
    "    manager.modify('beta', beta)\n",
    "    manager.modify('type', type)\n",
    "    manager.modify('simTime', 1000)\n",
    "    manager.modify('crash_probs', faulty_nodes)\n",
    "    manager.modify('byzantine_nodes', num_byzantine)\n",
    "    manager.set_up()\n",
    "\n",
    "\n",
    "    # Start the simulation and measure the runtime\n",
    "    t = datetime.now()\n",
    "    print(\"Simulation started...\")\n",
    "    manager.run()\n",
    "    runtime = datetime.now() - t\n",
    "    print(\"Simulation finished.\")\n",
    "    # Open a text file for writing the report\n",
    "\n",
    "    SimulationState.store_state(manager.sim)\n",
    "    Metrics.measure_all(SimulationState.blockchain_state)\n",
    "\n",
    "    # Redirect stdout to a string buffer, print the metrics, and then reset stdout\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer = io.StringIO()\n",
    "    Metrics.print_metrics()\n",
    "    sys.stdout = old_stdout\n",
    "        # Get the metrics results\n",
    "    metrics_result = Metrics.metrics_result()\n",
    "    \n",
    "    # Add the parameters to the metrics result dictionary\n",
    "    metrics_result.update({\n",
    "        \"Node\": Node,\n",
    "        \"Validator\": Validator,\n",
    "        \"Protocol\": Protocol,\n",
    "        \"Type\": type1,\n",
    "        \"Beta\": beta,\n",
    "        \"Faulty Nodes\": faulty_nodes,\n",
    "        \"Num Byzantine\": num_byzantine\n",
    "    })\n",
    "\n",
    "    return metrics_result\n",
    "\n",
    "print(\"--------------------\")    \n",
    "# Run the simulation with different parameters and collect the results\n",
    "results = []\n",
    "for number_byzantine1 in [0,1,2]:\n",
    "    for faulty_nodes1 in [0,1,2]:\n",
    "       for type1 in [\"broadcast\",\"smallworld\",\"gossip\"]:\n",
    "            for Node1 in [6,9,12]:\n",
    "                for Validator1 in [1]:\n",
    "                    for Protocol1 in ['PBFT', 'BigFoot']:\n",
    "                        for Runtime1 in [1000]:\n",
    "                            print(f\"Running simulation with Node={Node1}, Validator={Validator1}, Protocol={Protocol1}, Runtime={Runtime1}, type={type1}, beta=0.5, faulty_nodes={faulty_nodes1}, num_byzantine={number_byzantine1}\")\n",
    "                            result = run1(Node=Node1, Validator=Validator1, Protocol=Protocol1,type=type1, beta=0.5,faulty_nodes=faulty_nodes1,num_byzantine=number_byzantine1)\n",
    "                            results.append(result)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "def plot_simulation_results(df):\n",
    "    # Parameters for the x-axis\n",
    "    x_params = ['Node', 'Validator', 'Protocol', 'faulty_nodes', 'type']\n",
    "    # Metrics to plot on the y-axis\n",
    "    y_metrics = ['Average Latency', 'Average Throughput']\n",
    "    \n",
    "    # Set the style of matplotlib to emulate ggsci style\n",
    "    plt.style.use('ggplot')  # 'ggplot' style has a good scientific look\n",
    "    sns.set_palette(\"colorblind\")  # Color palette that is colorblind accessible\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(len(y_metrics), len(x_params), figsize=(20, 10))\n",
    "\n",
    "    for i, metric in enumerate(y_metrics):\n",
    "        for j, param in enumerate(x_params):\n",
    "            sns.barplot(data=df, x=param, y=metric, ax=axs[i, j], capsize=.05)\n",
    "            axs[i, j].set_title(f'{metric} over different {param}')\n",
    "            axs[i, j].set_xlabel(param)\n",
    "            axs[i, j].set_ylabel(metric)\n",
    "            for item in axs[i, j].get_xticklabels():\n",
    "                item.set_rotation(45)  # Rotate x labels for better readability\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Convert the results to a DataFrame with appropriate columns\n",
    "df = pd.DataFrame(results)\n",
    "# Make sure to include all parameters and metrics in the DataFrame\n",
    "expected_columns = ['Node', 'Validator', 'Protocol', 'Type', 'Beta', 'Faulty Nodes', 'Num Byzantine', \n",
    "                    'Average Latency', 'Latency Variance', 'Average Throughput', 'Throughput Variance']\n",
    "assert all(column in df.columns for column in expected_columns), \"DataFrame is missing expected columns\"\n",
    "\n",
    "# Call the function to plot the results\n",
    "plot_simulation_results(df)\n",
    "\n",
    "# def plot_simulation_results(df):\n",
    "#     # Set a larger figure size for readability\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "\n",
    "#     # Define the metrics to plot\n",
    "#     metrics_to_plot = ['Average Latency', 'Latency Variance', 'Average Throughput', 'Throughput Variance']\n",
    "\n",
    "#     # Create a subplot for each metric\n",
    "#     for i, metric in enumerate(metrics_to_plot, 1):\n",
    "#         plt.subplot(2, 2, i)  # 2x2 grid, position i\n",
    "#         plt.bar(df.index, df[metric], yerr=df.get(metric + ' Variance', 0), capsize=5)\n",
    "#         plt.title(metric)\n",
    "#         plt.xlabel('Simulation Run')\n",
    "#         plt.ylabel(metric.split()[1])\n",
    "#         plt.xticks(rotation=45)  # Rotate x labels for better readability if needed\n",
    "    \n",
    "#     # Adjust layout and show the plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function to plot the results\n",
    "# plot_simulation_results(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation started...\n",
      "Simulation finished.\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m Validator \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.5\u001b[39m]:\n\u001b[1;32m     78\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m Protocol \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBFT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigFoot\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 79\u001b[0m                         result \u001b[38;5;241m=\u001b[39m \u001b[43mrun1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValidator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mValidator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProtocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mProtocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaulty_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaulty_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_byzantine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_byzantine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m                         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Convert the results to a DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mrun1\u001b[0;34m(Node, Validator, Protocol, type, beta, faulty_nodes, num_byzantine)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Open a text file for writing the report\u001b[39;00m\n\u001b[1;32m     47\u001b[0m SimulationState\u001b[38;5;241m.\u001b[39mstore_state(manager\u001b[38;5;241m.\u001b[39msim)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimulationState\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockchain_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Redirect stdout to a string buffer, print the metrics, and then reset stdout\u001b[39;00m\n\u001b[1;32m     51\u001b[0m old_stdout \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/Documents/GitHub/SymBChainSim101/src/Chain/Metrics.py:52\u001b[0m, in \u001b[0;36mMetrics.measure_all\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_all\u001b[39m(state):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_latency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     Metrics\u001b[38;5;241m.\u001b[39mmeasure_throughput(state)\n",
      "File \u001b[0;32m~/Documents/GitHub/SymBChainSim101/src/Chain/Metrics.py:94\u001b[0m, in \u001b[0;36mMetrics.measure_latency\u001b[0;34m(bc_state)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m node_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblockchain\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     90\u001b[0m     Metrics\u001b[38;5;241m.\u001b[39mlatency[node_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m][b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m     91\u001b[0m         [b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_added\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransactions\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     92\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m Metrics\u001b[38;5;241m.\u001b[39mlatency[node_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_lat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_lat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatency\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BlockChain/lib/python3.10/statistics.py:328\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    326\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean requires at least one data point\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    329\u001b[0m T, total, count \u001b[38;5;241m=\u001b[39m _sum(data)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m count \u001b[38;5;241m==\u001b[39m n\n",
      "\u001b[0;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Set the seed for random number generation\n",
    "# seed = 5\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# def run1(Node=10, Validator=0.1, Protocol='BigFoot', type=\"broadcast\", beta=0.5, faulty_nodes=0, num_byzantine=0):\n",
    "#     \"\"\"\n",
    "#     Runs the simulation with the given parameters and returns the average metrics and their variances.\n",
    "\n",
    "#     Parameters:\n",
    "#     - Node (int): The number of nodes in the simulation.\n",
    "#     - Validator (float): The probability of a node being a validator.\n",
    "#     - Protocol (str): The consensus protocol to use ('BigFoot' or 'PBFT').\n",
    "#     - type (str): The type of message passing ('gossip', 'broadcast', 'smallworld').\n",
    "#     - beta (float): The beta parameter for the simulation.\n",
    "#     - faulty_nodes (int): The number of faulty nodes in the simulation.\n",
    "#     - num_byzantine (int): The number of byzantine nodes in the simulation.\n",
    "\n",
    "#     Returns:\n",
    "#     dict: A dictionary containing the simulation parameters and resulting metrics.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Create a Manager object and set up the simulation\n",
    "#     manager = Manager()\n",
    "#     tools.set_env_vars_from_config()\n",
    "#     Parameters.load_params_from_config()\n",
    "#     # Use the modify method to set the parameters\n",
    "#     manager.modify('Nn', Node)\n",
    "#     manager.modify('alpha', Validator)\n",
    "#     manager.modify('init_CP', Protocol)\n",
    "#     manager.modify('beta', beta)\n",
    "#     manager.modify('type', type)\n",
    "#     manager.modify('simTime', 2000)\n",
    "#     manager.modify('crash_probs', faulty_nodes)\n",
    "#     manager.modify('byzantine_nodes', num_byzantine)\n",
    "#     manager.set_up()\n",
    "\n",
    "\n",
    "#     # Start the simulation and measure the runtime\n",
    "#     t = datetime.now()\n",
    "#     print(\"Simulation started...\")\n",
    "#     manager.run()\n",
    "#     runtime = datetime.now() - t\n",
    "#     print(\"Simulation finished.\")\n",
    "#     # Open a text file for writing the report\n",
    "\n",
    "#     SimulationState.store_state(manager.sim)\n",
    "#     Metrics.measure_all(SimulationState.blockchain_state)\n",
    "\n",
    "#     # Redirect stdout to a string buffer, print the metrics, and then reset stdout\n",
    "#     old_stdout = sys.stdout\n",
    "#     sys.stdout = buffer = io.StringIO()\n",
    "#     Metrics.print_metrics()\n",
    "#     sys.stdout = old_stdout\n",
    "#     metrics_result = Metrics.metrics_result()\n",
    "\n",
    "#     # Add the parameters to the metrics result dictionary\n",
    "#     metrics_result.update({\n",
    "#         \"Node\": Node,\n",
    "#         \"Validator\": Validator,\n",
    "#         \"Protocol\": Protocol,\n",
    "#         \"Type\": type,\n",
    "#         \"Beta\": beta,\n",
    "#         \"Faulty Nodes\": faulty_nodes,\n",
    "#         \"Num Byzantine\": num_byzantine\n",
    "#     })\n",
    "\n",
    "#     return metrics_result\n",
    "\n",
    "    \n",
    "# # Run the simulation with different parameters and collect the results\n",
    "# results = []\n",
    "# for num_byzantine in [0, 1, 2, 3]:\n",
    "#     for faulty_nodes in [0, 1, 2, 3]:\n",
    "#         for type in [\"gossip\", \"broadcast\", \"smallworld\"]:\n",
    "#             for Node in [6, 9, 12]:\n",
    "#                 for Validator in [0.5]:\n",
    "#                     for Protocol in ['PBFT', 'BigFoot']:\n",
    "#                         result = run1(Node=Node, Validator=Validator, Protocol=Protocol, type=type, beta=0.5, faulty_nodes=faulty_nodes, num_byzantine=num_byzantine)\n",
    "#                         results.append(result)\n",
    "# # Convert the results to a DataFrame\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# def plot_simulation_results(df):\n",
    "#     # Parameters for the x-axis\n",
    "#     x_params = ['Node', 'Validator', 'Protocol', 'faulty_nodes', 'type']\n",
    "#     # Metrics to plot on the y-axis\n",
    "#     y_metrics = ['Average Latency', 'Average Throughput']\n",
    "    \n",
    "#     # Set the style of matplotlib to emulate ggsci style\n",
    "#     plt.style.use('ggplot')  # 'ggplot' style has a good scientific look\n",
    "#     sns.set_palette(\"colorblind\")  # Color palette that is colorblind accessible\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig, axs = plt.subplots(len(y_metrics), len(x_params), figsize=(20, 10))\n",
    "\n",
    "#     for i, metric in enumerate(y_metrics):\n",
    "#         for j, param in enumerate(x_params):\n",
    "#             sns.barplot(data=df, x=param, y=metric, ax=axs[i, j], capsize=.05)\n",
    "#             axs[i, j].set_title(f'{metric} over different {param}')\n",
    "#             axs[i, j].set_xlabel(param)\n",
    "#             axs[i, j].set_ylabel(metric)\n",
    "#             for item in axs[i, j].get_xticklabels():\n",
    "#                 item.set_rotation(45)  # Rotate x labels for better readability\n",
    "\n",
    "#     # Adjust layout and show the plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Convert the results to a DataFrame with appropriate columns\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "# # Call the function to plot the results\n",
    "# plot_simulation_results(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlockChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
